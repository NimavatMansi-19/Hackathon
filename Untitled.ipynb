{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa15266-a1d7-4e2a-87da-275016b10250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement random (from versions: none)\n",
      "ERROR: No matching distribution found for random\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ca7b2e-7b12-44fe-a8df-1671708346c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\manshi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.14.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\manshi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\manshi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\manshi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.7.1-cp313-cp313-win_amd64.whl (216.1 MB)\n",
      "   ---------------------------------------- 0.0/216.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/216.1 MB 14.4 MB/s eta 0:00:15\n",
      "    --------------------------------------- 5.0/216.1 MB 14.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 7.6/216.1 MB 13.7 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 11.0/216.1 MB 14.4 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 14.9/216.1 MB 15.3 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 18.4/216.1 MB 15.7 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 20.2/216.1 MB 15.8 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 24.6/216.1 MB 15.5 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 27.8/216.1 MB 15.3 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 31.7/216.1 MB 15.6 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 35.4/216.1 MB 15.8 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 38.8/216.1 MB 15.8 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 42.7/216.1 MB 16.0 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 45.6/216.1 MB 15.8 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 49.8/216.1 MB 15.9 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 53.2/216.1 MB 15.9 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 56.1/216.1 MB 15.8 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 58.7/216.1 MB 15.5 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 62.4/216.1 MB 15.6 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 66.1/216.1 MB 15.7 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 69.5/216.1 MB 15.7 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 73.9/216.1 MB 15.9 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 77.3/216.1 MB 16.0 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 81.0/216.1 MB 16.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 84.7/216.1 MB 16.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 88.3/216.1 MB 16.1 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 91.8/216.1 MB 16.1 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 96.5/216.1 MB 16.3 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 100.7/216.1 MB 16.4 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 105.4/216.1 MB 16.7 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 109.6/216.1 MB 16.8 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 113.5/216.1 MB 16.8 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 117.7/216.1 MB 16.9 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 120.8/216.1 MB 16.9 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 124.8/216.1 MB 16.9 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 129.2/216.1 MB 17.0 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 132.4/216.1 MB 17.0 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 136.1/216.1 MB 17.0 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 139.7/216.1 MB 17.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 144.2/216.1 MB 17.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 147.3/216.1 MB 16.9 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 150.7/216.1 MB 16.9 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 154.1/216.1 MB 16.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 157.3/216.1 MB 16.9 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 161.0/216.1 MB 16.9 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 163.8/216.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 167.0/216.1 MB 16.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 169.3/216.1 MB 16.6 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 171.7/216.1 MB 16.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 174.3/216.1 MB 16.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 177.5/216.1 MB 16.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 180.1/216.1 MB 16.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 183.0/216.1 MB 16.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 186.1/216.1 MB 16.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 188.5/216.1 MB 16.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 192.2/216.1 MB 16.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 196.1/216.1 MB 16.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 199.0/216.1 MB 16.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 203.2/216.1 MB 16.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 207.6/216.1 MB 16.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.1/216.1 MB 16.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  215.7/216.1 MB 16.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  216.0/216.1 MB 16.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  216.0/216.1 MB 16.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 216.1/216.1 MB 15.7 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 3.9/6.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 16.9 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 14.8 MB/s eta 0:00:00\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 17.2 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch\n",
      "\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   -------------------- ------------------- 3/6 [fsspec]\n",
      "   -------------------- ------------------- 3/6 [fsspec]\n",
      "   -------------------- ------------------- 3/6 [fsspec]\n",
      "   -------------------- ------------------- 3/6 [fsspec]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   ---------------------------------------- 6/6 [torch]\n",
      "\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.7.0 mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75ca742a-f8d9-4ea5-901e-2d07d1e5c540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 50, Avg Loss: 0.0021\n",
      "Epoch 100, Avg Loss: 0.0008\n",
      "Epoch 150, Avg Loss: 0.0004\n",
      "Epoch 200, Avg Loss: 0.0003\n",
      "Epoch 250, Avg Loss: 0.0002\n",
      "Epoch 300, Avg Loss: 0.0001\n",
      "Epoch 350, Avg Loss: 0.0001\n",
      "Epoch 400, Avg Loss: 0.0001\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Dialog pairs: (input, response)\n",
    "data_pairs = [\n",
    "    (\"Hi\", \"Hello! What is your name?\"),\n",
    "    (\"My name is John\", \"Nice to meet you John. How old are you?\"),\n",
    "    (\"I am 30 years old\", \"Got it. What is your gender?\"),\n",
    "    (\"Male\", \"Please describe your symptoms.\"),\n",
    "    (\"I have a headache and fever\", \"Based on your symptoms, we recommend you to contact Dr. Smith, General Physician. Phone: 555-1234\"),\n",
    "    (\"Thank you\", \"You're welcome! Take care!\"),\n",
    "    (\"Bye\", \"Goodbye! Stay healthy!\"),\n",
    "]\n",
    "\n",
    "# ---------- Vocabulary ----------\n",
    "def tokenize(text):\n",
    "    return text.lower().replace('.', '').replace(',', '').split()\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2idx = {\"<PAD>\":0, \"<SOS>\":1, \"<EOS>\":2, \"<UNK>\":3}\n",
    "        self.idx2word = {0:\"<PAD>\", 1:\"<SOS>\", 2:\"<EOS>\", 3:\"<UNK>\"}\n",
    "        self.num_words = 4\n",
    "    \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in tokenize(sentence):\n",
    "            self.add_word(word)\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.num_words\n",
    "            self.idx2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "    \n",
    "    def sentence_to_indices(self, sentence):\n",
    "        return [self.word2idx.get(word, self.word2idx[\"<UNK>\"]) for word in tokenize(sentence)]\n",
    "    \n",
    "    def indices_to_sentence(self, indices):\n",
    "        return ' '.join([self.idx2word.get(idx, \"<UNK>\") for idx in indices])\n",
    "\n",
    "vocab = Vocab()\n",
    "for input_text, output_text in data_pairs:\n",
    "    vocab.add_sentence(input_text)\n",
    "    vocab.add_sentence(output_text)\n",
    "\n",
    "# ---------- Dataset ----------\n",
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, pairs, vocab):\n",
    "        self.pairs = pairs\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq = self.vocab.sentence_to_indices(self.pairs[idx][0]) + [self.vocab.word2idx[\"<EOS>\"]]\n",
    "        output_seq = [self.vocab.word2idx[\"<SOS>\"]] + self.vocab.sentence_to_indices(self.pairs[idx][1]) + [self.vocab.word2idx[\"<EOS>\"]]\n",
    "        return torch.tensor(input_seq), torch.tensor(output_seq)\n",
    "\n",
    "dataset = ChatDataset(data_pairs, vocab)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=lambda x: x)\n",
    "\n",
    "def pad_sequences(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "    input_lens = [len(seq) for seq in inputs]\n",
    "    target_lens = [len(seq) for seq in targets]\n",
    "\n",
    "    inputs_pad = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=vocab.word2idx[\"<PAD>\"])\n",
    "    targets_pad = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=vocab.word2idx[\"<PAD>\"])\n",
    "    return inputs_pad, torch.tensor(input_lens), targets_pad, torch.tensor(target_lens)\n",
    "\n",
    "# ---------- Models ----------\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input_seqs, input_lengths):\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        outputs, hidden = self.gru(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        return outputs, hidden\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, emb_size, hidden_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, emb_size)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input_step, hidden):\n",
    "        # input_step: (batch_size, 1)\n",
    "        embedded = self.embedding(input_step)  # (batch_size, 1, emb_size)\n",
    "        output, hidden = self.gru(embedded, hidden)  # (batch_size, 1, hidden_size)\n",
    "        output = self.log_softmax(self.out(output))  # (batch_size, 1, vocab_size)\n",
    "        return output, hidden\n",
    "\n",
    "# ---------- Training ----------\n",
    "def train(input_tensor, input_lengths, target_tensor, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_target_len):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    batch_size = input_tensor.size(0)\n",
    "    encoder_outputs, encoder_hidden = encoder(input_tensor, input_lengths)\n",
    "\n",
    "    decoder_input = torch.full((batch_size, 1), vocab.word2idx[\"<SOS>\"], dtype=torch.long, device=input_tensor.device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    loss = 0\n",
    "\n",
    "    for t in range(max_target_len):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)  # (batch, 1, vocab_size)\n",
    "        decoder_output = decoder_output.squeeze(1)  # (batch, vocab_size)\n",
    "\n",
    "        if t < target_tensor.size(1):\n",
    "            target = target_tensor[:, t]\n",
    "        else:\n",
    "            target = torch.full((batch_size,), vocab.word2idx[\"<PAD>\"], dtype=torch.long, device=input_tensor.device)\n",
    "\n",
    "        loss += criterion(decoder_output, target)\n",
    "\n",
    "        teacher_force = random.random() < 0.5\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        if teacher_force and t < target_tensor.size(1):\n",
    "            decoder_input = target.unsqueeze(1)\n",
    "        else:\n",
    "            decoder_input = topi.detach()\n",
    "\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    return loss.item() / max_target_len\n",
    "\n",
    "# ---------- Hyperparameters ----------\n",
    "EMB_SIZE = 64\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_EPOCHS = 400\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder = EncoderRNN(vocab.num_words, EMB_SIZE, HIDDEN_SIZE).to(device)\n",
    "decoder = DecoderRNN(vocab.num_words, EMB_SIZE, HIDDEN_SIZE).to(device)\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=LEARNING_RATE)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.NLLLoss(ignore_index=vocab.word2idx[\"<PAD>\"])\n",
    "\n",
    "# ---------- Training Loop ----------\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        inputs_pad, input_lens, targets_pad, target_lens = pad_sequences(batch)\n",
    "        inputs_pad = inputs_pad.to(device)\n",
    "        targets_pad = targets_pad.to(device)\n",
    "        input_lens = input_lens.to(device)\n",
    "        target_lens = target_lens.to(device)\n",
    "        max_target_len = max(target_lens)\n",
    "\n",
    "        loss = train(inputs_pad, input_lens, targets_pad, target_lens, encoder, decoder,\n",
    "                     encoder_optimizer, decoder_optimizer, criterion, max_target_len)\n",
    "        total_loss += loss\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Avg Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# ---------- Evaluation ----------\n",
    "def evaluate(sentence, encoder, decoder, max_length=50):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_indices = vocab.sentence_to_indices(sentence) + [vocab.word2idx[\"<EOS>\"]]\n",
    "        input_tensor = torch.tensor(input_indices, dtype=torch.long, device=device).unsqueeze(0)\n",
    "        input_length = torch.tensor([len(input_indices)], device=device)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor, input_length)\n",
    "        decoder_input = torch.tensor([[vocab.word2idx[\"<SOS>\"]]], device=device)\n",
    "        decoder_hidden = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc3157-e17a-40f0-a029-501df7cdeedb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
